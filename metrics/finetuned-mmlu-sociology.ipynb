{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q -U deepeval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:56:53.222080Z","iopub.execute_input":"2025-01-03T09:56:53.222444Z","iopub.status.idle":"2025-01-03T09:57:15.754770Z","shell.execute_reply.started":"2025-01-03T09:56:53.222418Z","shell.execute_reply":"2025-01-03T09:57:15.753617Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m576.5/576.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.7/325.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndistributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%capture\n!pip install --no-deps xformers trl peft accelerate bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:57:15.756519Z","iopub.execute_input":"2025-01-03T09:57:15.756881Z","iopub.status.idle":"2025-01-03T09:57:21.281820Z","shell.execute_reply.started":"2025-01-03T09:57:15.756849Z","shell.execute_reply":"2025-01-03T09:57:21.280602Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install -q -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:57:21.283711Z","iopub.execute_input":"2025-01-03T09:57:21.284014Z","iopub.status.idle":"2025-01-03T09:57:25.043166Z","shell.execute_reply.started":"2025-01-03T09:57:21.283993Z","shell.execute_reply":"2025-01-03T09:57:25.042191Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install -q --upgrade peft trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:57:25.044830Z","iopub.execute_input":"2025-01-03T09:57:25.045058Z","iopub.status.idle":"2025-01-03T09:57:44.749567Z","shell.execute_reply.started":"2025-01-03T09:57:25.045039Z","shell.execute_reply":"2025-01-03T09:57:44.748706Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install -q lm-format-enforcer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:57:44.750542Z","iopub.execute_input":"2025-01-03T09:57:44.750778Z","iopub.status.idle":"2025-01-03T09:57:49.039197Z","shell.execute_reply.started":"2025-01-03T09:57:44.750759Z","shell.execute_reply":"2025-01-03T09:57:49.038294Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install -q --upgrade pymilvus openai requests tqdm pandas deepeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:57:49.040167Z","iopub.execute_input":"2025-01-03T09:57:49.040432Z","iopub.status.idle":"2025-01-03T09:58:06.722097Z","shell.execute_reply.started":"2025-01-03T09:57:49.040410Z","shell.execute_reply":"2025-01-03T09:58:06.720971Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.3 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nread_key = user_secrets.get_secret(\"HF_READ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:58:06.723122Z","iopub.execute_input":"2025-01-03T09:58:06.723409Z","iopub.status.idle":"2025-01-03T09:58:06.887254Z","shell.execute_reply.started":"2025-01-03T09:58:06.723388Z","shell.execute_reply":"2025-01-03T09:58:06.886167Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token= read_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:58:06.888474Z","iopub.execute_input":"2025-01-03T09:58:06.888861Z","iopub.status.idle":"2025-01-03T09:58:07.491227Z","shell.execute_reply.started":"2025-01-03T09:58:06.888823Z","shell.execute_reply":"2025-01-03T09:58:07.490464Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import json\nfrom pydantic import BaseModel\nimport torch\nfrom lmformatenforcer import JsonSchemaParser\nfrom lmformatenforcer.integrations.transformers import (\n    build_transformers_prefix_allowed_tokens_fn,\n)\nfrom transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n\nfrom deepeval.models import DeepEvalBaseLLM\n\n\nclass CustomModel(DeepEvalBaseLLM):\n    def __init__(self):\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_use_double_quant=True,\n        )\n\n        model_4bit = AutoModelForCausalLM.from_pretrained(\n            \"JefiRyan/Gemma-2B-Unsloth-mental-health-merged\",\n            device_map=\"auto\",\n            quantization_config=quantization_config,\n        )\n        tokenizer = AutoTokenizer.from_pretrained(\n            \"JefiRyan/Gemma-2B-Unsloth-mental-health-merged\"\n        )\n\n        self.model = model_4bit\n        self.tokenizer = tokenizer\n\n    def load_model(self):\n        return self.model\n\n    def generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n        model = self.load_model()\n        # Initialize the pipeline for text generation\n        gen_pipeline = pipeline(\n            \"text-generation\",\n            model=model,\n            tokenizer=self.tokenizer,\n            use_cache=True,\n            device_map=\"auto\",\n            max_length=2500,\n            do_sample=True,\n            top_k=5,\n            num_return_sequences=1,\n            eos_token_id=self.tokenizer.eos_token_id,\n            pad_token_id=self.tokenizer.eos_token_id,\n        )\n\n        # Create parser required for JSON confinement using lmformatenforcer\n        parser = JsonSchemaParser(schema.schema())\n        prefix_function = build_transformers_prefix_allowed_tokens_fn(\n            gen_pipeline.tokenizer, parser\n        )\n\n        # Output and load valid JSON\n        output_dict = gen_pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n        output = output_dict[0][\"generated_text\"][len(prompt):]\n        json_result = json.loads(output)\n\n        # Return valid JSON object according to the schema DeepEval supplied\n        return schema(**json_result)\n\n    async def a_generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n        return self.generate(prompt, schema)\n\n    def get_model_name(self):\n        return \"Gemma-2B Unsloth Finetuned\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:58:07.493277Z","iopub.execute_input":"2025-01-03T09:58:07.493518Z","iopub.status.idle":"2025-01-03T09:58:33.126516Z","shell.execute_reply.started":"2025-01-03T09:58:07.493498Z","shell.execute_reply":"2025-01-03T09:58:33.125718Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from deepeval.benchmarks import MMLU\nfrom deepeval.benchmarks.tasks import MMLUTask\n\ncustom_llm = CustomModel()\n\nmm_tasks = [\n    MMLUTask.SOCIOLOGY,\n]\n\nbenchmark = MMLU(\n    tasks=mm_tasks,\n    n_shots=3\n)\n\n\nbenchmark.evaluate(model=custom_llm)\nprint(benchmark.overall_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T09:58:33.127644Z","iopub.execute_input":"2025-01-03T09:58:33.127989Z","iopub.status.idle":"2025-01-03T10:58:24.782900Z","shell.execute_reply.started":"2025-01-03T09:58:33.127958Z","shell.execute_reply":"2025-01-03T10:58:24.782042Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/753 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54f4ed3c490941bc9818d2db70ec0182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"609cc3b4977a4ab2a010231903a28f23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4552efd505584b2aa61e9f564fd9ea76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ba7ba2e71224453831ce5b5f559a44e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72cffe42fc374fc7be448c0e65abd190"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b7ccfd1298b4a618faece2022f8da6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"685b235de79a473da51af8bdffef9f9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd79cc6460e7453ea3a34e7ade6d3a24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890fada768e048b994fd44c48e6e045d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"520c16f2bc2346f38af1c7cd1df87c4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d07af2266c041369f9def1a85856c5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/28.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6ce073b560a4e6694b753c8620c3b3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mmlu.py:   0%|          | 0.00/5.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1583f1f86b1342e8925f32459b2d0ff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2fc50aee0b34bed9e298fb0b44ac538"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/201 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"934bb3b416dc4df5a6680dd5987e8d41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/22 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"676a06f24d6444be82c615265bdeea51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4680841bcc647e3827b4d5343988dc2"}},"metadata":{}},{"name":"stderr","text":"Processing sociology:   0%|          | 0/201 [00:00<?, ?it/s]Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nProcessing sociology:   0%|          | 1/201 [00:20<1:08:35, 20.58s/it]Device set to use cuda:0\nProcessing sociology:   1%|          | 2/201 [00:37<1:00:42, 18.30s/it]Device set to use cuda:0\nProcessing sociology:   1%|▏         | 3/201 [00:55<1:00:31, 18.34s/it]Device set to use cuda:0\nProcessing sociology:   2%|▏         | 4/201 [01:12<57:54, 17.64s/it]  Device set to use cuda:0\nProcessing sociology:   2%|▏         | 5/201 [01:29<56:42, 17.36s/it]Device set to use cuda:0\nProcessing sociology:   3%|▎         | 6/201 [01:46<55:59, 17.23s/it]Device set to use cuda:0\nProcessing sociology:   3%|▎         | 7/201 [02:01<54:13, 16.77s/it]Device set to use cuda:0\nProcessing sociology:   4%|▍         | 8/201 [02:19<54:18, 16.89s/it]Device set to use cuda:0\nProcessing sociology:   4%|▍         | 9/201 [02:35<53:57, 16.86s/it]Device set to use cuda:0\nProcessing sociology:   5%|▍         | 10/201 [02:53<54:26, 17.10s/it]Device set to use cuda:0\nProcessing sociology:   5%|▌         | 11/201 [03:11<54:57, 17.35s/it]Device set to use cuda:0\nProcessing sociology:   6%|▌         | 12/201 [03:28<54:40, 17.36s/it]Device set to use cuda:0\nProcessing sociology:   6%|▋         | 13/201 [03:45<53:21, 17.03s/it]Device set to use cuda:0\nProcessing sociology:   7%|▋         | 14/201 [04:01<52:39, 16.89s/it]Device set to use cuda:0\nProcessing sociology:   7%|▋         | 15/201 [04:19<53:21, 17.21s/it]Device set to use cuda:0\nProcessing sociology:   8%|▊         | 16/201 [04:36<52:41, 17.09s/it]Device set to use cuda:0\nProcessing sociology:   8%|▊         | 17/201 [04:53<52:23, 17.08s/it]Device set to use cuda:0\nProcessing sociology:   9%|▉         | 18/201 [05:10<52:05, 17.08s/it]Device set to use cuda:0\nProcessing sociology:   9%|▉         | 19/201 [05:27<51:57, 17.13s/it]Device set to use cuda:0\nProcessing sociology:  10%|▉         | 20/201 [05:45<52:22, 17.36s/it]Device set to use cuda:0\nProcessing sociology:  10%|█         | 21/201 [06:01<50:42, 16.90s/it]Device set to use cuda:0\nProcessing sociology:  11%|█         | 22/201 [06:18<50:19, 16.87s/it]Device set to use cuda:0\nProcessing sociology:  11%|█▏        | 23/201 [06:35<50:38, 17.07s/it]Device set to use cuda:0\nProcessing sociology:  12%|█▏        | 24/201 [06:51<49:33, 16.80s/it]Device set to use cuda:0\nProcessing sociology:  12%|█▏        | 25/201 [07:08<49:21, 16.83s/it]Device set to use cuda:0\nProcessing sociology:  13%|█▎        | 26/201 [07:26<49:47, 17.07s/it]Device set to use cuda:0\nProcessing sociology:  13%|█▎        | 27/201 [07:42<48:33, 16.74s/it]Device set to use cuda:0\nProcessing sociology:  14%|█▍        | 28/201 [07:59<48:19, 16.76s/it]Device set to use cuda:0\nProcessing sociology:  14%|█▍        | 29/201 [08:16<48:01, 16.75s/it]Device set to use cuda:0\nProcessing sociology:  15%|█▍        | 30/201 [08:33<48:34, 17.04s/it]Device set to use cuda:0\nProcessing sociology:  15%|█▌        | 31/201 [08:51<48:50, 17.24s/it]Device set to use cuda:0\nProcessing sociology:  16%|█▌        | 32/201 [09:07<47:29, 16.86s/it]Device set to use cuda:0\nProcessing sociology:  16%|█▋        | 33/201 [09:23<46:57, 16.77s/it]Device set to use cuda:0\nProcessing sociology:  17%|█▋        | 34/201 [09:41<46:56, 16.87s/it]Device set to use cuda:0\nProcessing sociology:  17%|█▋        | 35/201 [09:57<46:33, 16.83s/it]Device set to use cuda:0\nProcessing sociology:  18%|█▊        | 36/201 [10:15<46:37, 16.96s/it]Device set to use cuda:0\nProcessing sociology:  18%|█▊        | 37/201 [10:31<45:38, 16.70s/it]Device set to use cuda:0\nProcessing sociology:  19%|█▉        | 38/201 [10:47<45:01, 16.57s/it]Device set to use cuda:0\nProcessing sociology:  19%|█▉        | 39/201 [11:04<45:04, 16.69s/it]Device set to use cuda:0\nProcessing sociology:  20%|█▉        | 40/201 [11:21<45:06, 16.81s/it]Device set to use cuda:0\nProcessing sociology:  20%|██        | 41/201 [11:38<44:57, 16.86s/it]Device set to use cuda:0\nProcessing sociology:  21%|██        | 42/201 [11:55<44:52, 16.93s/it]Device set to use cuda:0\nProcessing sociology:  21%|██▏       | 43/201 [12:12<44:27, 16.88s/it]Device set to use cuda:0\nProcessing sociology:  22%|██▏       | 44/201 [12:30<44:59, 17.20s/it]Device set to use cuda:0\nProcessing sociology:  22%|██▏       | 45/201 [12:48<45:23, 17.46s/it]Device set to use cuda:0\nProcessing sociology:  23%|██▎       | 46/201 [13:05<45:00, 17.42s/it]Device set to use cuda:0\nProcessing sociology:  23%|██▎       | 47/201 [13:22<44:09, 17.21s/it]Device set to use cuda:0\nProcessing sociology:  24%|██▍       | 48/201 [13:40<44:39, 17.51s/it]Device set to use cuda:0\nProcessing sociology:  24%|██▍       | 49/201 [13:57<43:54, 17.33s/it]Device set to use cuda:0\nProcessing sociology:  25%|██▍       | 50/201 [14:15<43:46, 17.39s/it]Device set to use cuda:0\nProcessing sociology:  25%|██▌       | 51/201 [14:33<44:20, 17.73s/it]Device set to use cuda:0\nProcessing sociology:  26%|██▌       | 52/201 [14:50<43:13, 17.41s/it]Device set to use cuda:0\nProcessing sociology:  26%|██▋       | 53/201 [15:08<43:52, 17.79s/it]Device set to use cuda:0\nProcessing sociology:  27%|██▋       | 54/201 [15:26<43:20, 17.69s/it]Device set to use cuda:0\nProcessing sociology:  27%|██▋       | 55/201 [15:43<42:49, 17.60s/it]Device set to use cuda:0\nProcessing sociology:  28%|██▊       | 56/201 [16:00<42:15, 17.49s/it]Device set to use cuda:0\nProcessing sociology:  28%|██▊       | 57/201 [16:18<41:51, 17.44s/it]Device set to use cuda:0\nProcessing sociology:  29%|██▉       | 58/201 [16:34<40:52, 17.15s/it]Device set to use cuda:0\nProcessing sociology:  29%|██▉       | 59/201 [16:50<39:37, 16.74s/it]Device set to use cuda:0\nProcessing sociology:  30%|██▉       | 60/201 [17:07<39:29, 16.81s/it]Device set to use cuda:0\nProcessing sociology:  30%|███       | 61/201 [17:24<39:36, 16.97s/it]Device set to use cuda:0\nProcessing sociology:  31%|███       | 62/201 [17:42<39:58, 17.25s/it]Device set to use cuda:0\nProcessing sociology:  31%|███▏      | 63/201 [18:01<40:21, 17.55s/it]Device set to use cuda:0\nProcessing sociology:  32%|███▏      | 64/201 [18:17<39:18, 17.22s/it]Device set to use cuda:0\nProcessing sociology:  32%|███▏      | 65/201 [18:35<39:29, 17.43s/it]Device set to use cuda:0\nProcessing sociology:  33%|███▎      | 66/201 [18:51<38:37, 17.17s/it]Device set to use cuda:0\nProcessing sociology:  33%|███▎      | 67/201 [19:09<38:36, 17.29s/it]Device set to use cuda:0\nProcessing sociology:  34%|███▍      | 68/201 [19:26<38:13, 17.25s/it]Device set to use cuda:0\nProcessing sociology:  34%|███▍      | 69/201 [19:44<38:02, 17.29s/it]Device set to use cuda:0\nProcessing sociology:  35%|███▍      | 70/201 [20:03<38:50, 17.79s/it]Device set to use cuda:0\nProcessing sociology:  35%|███▌      | 71/201 [20:20<38:14, 17.65s/it]Device set to use cuda:0\nProcessing sociology:  36%|███▌      | 72/201 [20:37<37:33, 17.47s/it]Device set to use cuda:0\nProcessing sociology:  36%|███▋      | 73/201 [20:54<37:11, 17.43s/it]Device set to use cuda:0\nProcessing sociology:  37%|███▋      | 74/201 [21:10<35:55, 16.97s/it]Device set to use cuda:0\nProcessing sociology:  37%|███▋      | 75/201 [21:28<36:08, 17.21s/it]Device set to use cuda:0\nProcessing sociology:  38%|███▊      | 76/201 [21:45<35:53, 17.23s/it]Device set to use cuda:0\nProcessing sociology:  38%|███▊      | 77/201 [22:02<35:36, 17.23s/it]Device set to use cuda:0\nProcessing sociology:  39%|███▉      | 78/201 [22:19<35:09, 17.15s/it]Device set to use cuda:0\nProcessing sociology:  39%|███▉      | 79/201 [22:37<34:59, 17.21s/it]Device set to use cuda:0\nProcessing sociology:  40%|███▉      | 80/201 [22:55<35:38, 17.67s/it]Device set to use cuda:0\nProcessing sociology:  40%|████      | 81/201 [23:13<35:08, 17.57s/it]Device set to use cuda:0\nProcessing sociology:  41%|████      | 82/201 [23:29<34:10, 17.23s/it]Device set to use cuda:0\nProcessing sociology:  41%|████▏     | 83/201 [23:47<34:01, 17.30s/it]Device set to use cuda:0\nProcessing sociology:  42%|████▏     | 84/201 [24:05<34:28, 17.68s/it]Device set to use cuda:0\nProcessing sociology:  42%|████▏     | 85/201 [24:22<33:46, 17.47s/it]Device set to use cuda:0\nProcessing sociology:  43%|████▎     | 86/201 [24:39<33:19, 17.39s/it]Device set to use cuda:0\nProcessing sociology:  43%|████▎     | 87/201 [24:56<32:22, 17.04s/it]Device set to use cuda:0\nProcessing sociology:  44%|████▍     | 88/201 [25:13<32:20, 17.18s/it]Device set to use cuda:0\nProcessing sociology:  44%|████▍     | 89/201 [25:30<31:51, 17.07s/it]Device set to use cuda:0\nProcessing sociology:  45%|████▍     | 90/201 [25:47<31:26, 16.99s/it]Device set to use cuda:0\nProcessing sociology:  45%|████▌     | 91/201 [26:04<31:17, 17.07s/it]Device set to use cuda:0\nProcessing sociology:  46%|████▌     | 92/201 [26:22<31:34, 17.38s/it]Device set to use cuda:0\nProcessing sociology:  46%|████▋     | 93/201 [26:40<31:43, 17.63s/it]Device set to use cuda:0\nProcessing sociology:  47%|████▋     | 94/201 [26:57<31:01, 17.40s/it]Device set to use cuda:0\nProcessing sociology:  47%|████▋     | 95/201 [27:14<30:36, 17.33s/it]Device set to use cuda:0\nProcessing sociology:  48%|████▊     | 96/201 [27:32<30:20, 17.34s/it]Device set to use cuda:0\nProcessing sociology:  48%|████▊     | 97/201 [27:48<29:29, 17.02s/it]Device set to use cuda:0\nProcessing sociology:  49%|████▉     | 98/201 [28:06<29:29, 17.18s/it]Device set to use cuda:0\nProcessing sociology:  49%|████▉     | 99/201 [28:23<29:32, 17.38s/it]Device set to use cuda:0\nProcessing sociology:  50%|████▉     | 100/201 [28:40<28:55, 17.18s/it]Device set to use cuda:0\nProcessing sociology:  50%|█████     | 101/201 [28:57<28:29, 17.09s/it]Device set to use cuda:0\nProcessing sociology:  51%|█████     | 102/201 [29:15<28:49, 17.47s/it]Device set to use cuda:0\nProcessing sociology:  51%|█████     | 103/201 [29:33<28:27, 17.42s/it]Device set to use cuda:0\nProcessing sociology:  52%|█████▏    | 104/201 [29:52<28:51, 17.85s/it]Device set to use cuda:0\nProcessing sociology:  52%|█████▏    | 105/201 [30:09<28:12, 17.63s/it]Device set to use cuda:0\nProcessing sociology:  53%|█████▎    | 106/201 [30:27<28:17, 17.87s/it]Device set to use cuda:0\nProcessing sociology:  53%|█████▎    | 107/201 [30:45<28:05, 17.93s/it]Device set to use cuda:0\nProcessing sociology:  54%|█████▎    | 108/201 [31:03<27:51, 17.97s/it]Device set to use cuda:0\nProcessing sociology:  54%|█████▍    | 109/201 [31:20<26:55, 17.56s/it]Device set to use cuda:0\nProcessing sociology:  55%|█████▍    | 110/201 [31:37<26:26, 17.44s/it]Device set to use cuda:0\nProcessing sociology:  55%|█████▌    | 111/201 [31:53<25:28, 16.98s/it]Device set to use cuda:0\nProcessing sociology:  56%|█████▌    | 112/201 [32:11<25:41, 17.32s/it]Device set to use cuda:0\nProcessing sociology:  56%|█████▌    | 113/201 [32:29<25:29, 17.38s/it]Device set to use cuda:0\nProcessing sociology:  57%|█████▋    | 114/201 [32:45<24:38, 16.99s/it]Device set to use cuda:0\nProcessing sociology:  57%|█████▋    | 115/201 [33:02<24:24, 17.03s/it]Device set to use cuda:0\nProcessing sociology:  58%|█████▊    | 116/201 [33:19<24:22, 17.20s/it]Device set to use cuda:0\nProcessing sociology:  58%|█████▊    | 117/201 [33:36<23:47, 17.00s/it]Device set to use cuda:0\nProcessing sociology:  59%|█████▊    | 118/201 [33:54<23:47, 17.20s/it]Device set to use cuda:0\nProcessing sociology:  59%|█████▉    | 119/201 [34:11<23:24, 17.13s/it]Device set to use cuda:0\nProcessing sociology:  60%|█████▉    | 120/201 [34:28<23:16, 17.24s/it]Device set to use cuda:0\nProcessing sociology:  60%|██████    | 121/201 [34:46<23:23, 17.54s/it]Device set to use cuda:0\nProcessing sociology:  61%|██████    | 122/201 [35:04<23:01, 17.49s/it]Device set to use cuda:0\nProcessing sociology:  61%|██████    | 123/201 [35:22<22:54, 17.62s/it]Device set to use cuda:0\nProcessing sociology:  62%|██████▏   | 124/201 [35:38<22:12, 17.31s/it]Device set to use cuda:0\nProcessing sociology:  62%|██████▏   | 125/201 [35:56<22:03, 17.41s/it]Device set to use cuda:0\nProcessing sociology:  63%|██████▎   | 126/201 [36:14<22:05, 17.68s/it]Device set to use cuda:0\nProcessing sociology:  63%|██████▎   | 127/201 [36:31<21:30, 17.43s/it]Device set to use cuda:0\nProcessing sociology:  64%|██████▎   | 128/201 [36:47<20:42, 17.02s/it]Device set to use cuda:0\nProcessing sociology:  64%|██████▍   | 129/201 [37:04<20:35, 17.16s/it]Device set to use cuda:0\nProcessing sociology:  65%|██████▍   | 130/201 [37:22<20:27, 17.29s/it]Device set to use cuda:0\nProcessing sociology:  65%|██████▌   | 131/201 [37:38<19:51, 17.03s/it]Device set to use cuda:0\nProcessing sociology:  66%|██████▌   | 132/201 [37:57<20:00, 17.39s/it]Device set to use cuda:0\nProcessing sociology:  66%|██████▌   | 133/201 [38:14<19:36, 17.30s/it]Device set to use cuda:0\nProcessing sociology:  67%|██████▋   | 134/201 [38:31<19:06, 17.11s/it]Device set to use cuda:0\nProcessing sociology:  67%|██████▋   | 135/201 [38:47<18:45, 17.06s/it]Device set to use cuda:0\nProcessing sociology:  68%|██████▊   | 136/201 [39:04<18:24, 16.99s/it]Device set to use cuda:0\nProcessing sociology:  68%|██████▊   | 137/201 [39:21<17:58, 16.85s/it]Device set to use cuda:0\nProcessing sociology:  69%|██████▊   | 138/201 [39:38<17:51, 17.01s/it]Device set to use cuda:0\nProcessing sociology:  69%|██████▉   | 139/201 [39:55<17:32, 16.98s/it]Device set to use cuda:0\nProcessing sociology:  70%|██████▉   | 140/201 [40:12<17:22, 17.10s/it]Device set to use cuda:0\nProcessing sociology:  70%|███████   | 141/201 [40:30<17:16, 17.27s/it]Device set to use cuda:0\nProcessing sociology:  71%|███████   | 142/201 [40:47<16:43, 17.02s/it]Device set to use cuda:0\nProcessing sociology:  71%|███████   | 143/201 [41:04<16:31, 17.09s/it]Device set to use cuda:0\nProcessing sociology:  72%|███████▏  | 144/201 [41:20<16:06, 16.96s/it]Device set to use cuda:0\nProcessing sociology:  72%|███████▏  | 145/201 [41:37<15:36, 16.72s/it]Device set to use cuda:0\nProcessing sociology:  73%|███████▎  | 146/201 [41:53<15:18, 16.70s/it]Device set to use cuda:0\nProcessing sociology:  73%|███████▎  | 147/201 [42:10<15:06, 16.78s/it]Device set to use cuda:0\nProcessing sociology:  74%|███████▎  | 148/201 [42:27<14:55, 16.89s/it]Device set to use cuda:0\nProcessing sociology:  74%|███████▍  | 149/201 [42:44<14:39, 16.92s/it]Device set to use cuda:0\nProcessing sociology:  75%|███████▍  | 150/201 [43:02<14:31, 17.10s/it]Device set to use cuda:0\nProcessing sociology:  75%|███████▌  | 151/201 [43:19<14:14, 17.09s/it]Device set to use cuda:0\nProcessing sociology:  76%|███████▌  | 152/201 [43:36<14:02, 17.20s/it]Device set to use cuda:0\nProcessing sociology:  76%|███████▌  | 153/201 [43:53<13:39, 17.08s/it]Device set to use cuda:0\nProcessing sociology:  77%|███████▋  | 154/201 [44:10<13:20, 17.03s/it]Device set to use cuda:0\nProcessing sociology:  77%|███████▋  | 155/201 [44:27<13:04, 17.05s/it]Device set to use cuda:0\nProcessing sociology:  78%|███████▊  | 156/201 [44:45<12:59, 17.33s/it]Device set to use cuda:0\nProcessing sociology:  78%|███████▊  | 157/201 [45:03<12:45, 17.39s/it]Device set to use cuda:0\nProcessing sociology:  79%|███████▊  | 158/201 [45:21<12:32, 17.50s/it]Device set to use cuda:0\nProcessing sociology:  79%|███████▉  | 159/201 [45:38<12:15, 17.51s/it]Device set to use cuda:0\nProcessing sociology:  80%|███████▉  | 160/201 [45:54<11:44, 17.18s/it]Device set to use cuda:0\nProcessing sociology:  80%|████████  | 161/201 [46:11<11:25, 17.14s/it]Device set to use cuda:0\nProcessing sociology:  81%|████████  | 162/201 [46:30<11:25, 17.57s/it]Device set to use cuda:0\nProcessing sociology:  81%|████████  | 163/201 [46:47<10:54, 17.23s/it]Device set to use cuda:0\nProcessing sociology:  82%|████████▏ | 164/201 [47:03<10:27, 16.96s/it]Device set to use cuda:0\nProcessing sociology:  82%|████████▏ | 165/201 [47:21<10:19, 17.22s/it]Device set to use cuda:0\nProcessing sociology:  83%|████████▎ | 166/201 [47:39<10:09, 17.42s/it]Device set to use cuda:0\nProcessing sociology:  83%|████████▎ | 167/201 [47:55<09:39, 17.05s/it]Device set to use cuda:0\nProcessing sociology:  84%|████████▎ | 168/201 [48:11<09:19, 16.96s/it]Device set to use cuda:0\nProcessing sociology:  84%|████████▍ | 169/201 [48:28<08:54, 16.71s/it]Device set to use cuda:0\nProcessing sociology:  85%|████████▍ | 170/201 [48:44<08:37, 16.70s/it]Device set to use cuda:0\nProcessing sociology:  85%|████████▌ | 171/201 [49:02<08:27, 16.91s/it]Device set to use cuda:0\nProcessing sociology:  86%|████████▌ | 172/201 [49:18<08:03, 16.67s/it]Device set to use cuda:0\nProcessing sociology:  86%|████████▌ | 173/201 [49:34<07:45, 16.63s/it]Device set to use cuda:0\nProcessing sociology:  87%|████████▋ | 174/201 [49:51<07:33, 16.78s/it]Device set to use cuda:0\nProcessing sociology:  87%|████████▋ | 175/201 [50:09<07:24, 17.09s/it]Device set to use cuda:0\nProcessing sociology:  88%|████████▊ | 176/201 [50:27<07:09, 17.16s/it]Device set to use cuda:0\nProcessing sociology:  88%|████████▊ | 177/201 [50:43<06:47, 17.00s/it]Device set to use cuda:0\nProcessing sociology:  89%|████████▊ | 178/201 [50:59<06:25, 16.76s/it]Device set to use cuda:0\nProcessing sociology:  89%|████████▉ | 179/201 [51:16<06:06, 16.66s/it]Device set to use cuda:0\nProcessing sociology:  90%|████████▉ | 180/201 [51:33<05:52, 16.80s/it]Device set to use cuda:0\nProcessing sociology:  90%|█████████ | 181/201 [51:49<05:32, 16.65s/it]Device set to use cuda:0\nProcessing sociology:  91%|█████████ | 182/201 [52:06<05:17, 16.72s/it]Device set to use cuda:0\nProcessing sociology:  91%|█████████ | 183/201 [52:24<05:06, 17.01s/it]Device set to use cuda:0\nProcessing sociology:  92%|█████████▏| 184/201 [52:40<04:46, 16.86s/it]Device set to use cuda:0\nProcessing sociology:  92%|█████████▏| 185/201 [52:57<04:28, 16.77s/it]Device set to use cuda:0\nProcessing sociology:  93%|█████████▎| 186/201 [53:14<04:12, 16.82s/it]Device set to use cuda:0\nProcessing sociology:  93%|█████████▎| 187/201 [53:31<03:55, 16.82s/it]Device set to use cuda:0\nProcessing sociology:  94%|█████████▎| 188/201 [53:48<03:40, 16.94s/it]Device set to use cuda:0\nProcessing sociology:  94%|█████████▍| 189/201 [54:05<03:24, 17.01s/it]Device set to use cuda:0\nProcessing sociology:  95%|█████████▍| 190/201 [54:22<03:07, 17.04s/it]Device set to use cuda:0\nProcessing sociology:  95%|█████████▌| 191/201 [54:39<02:50, 17.08s/it]Device set to use cuda:0\nProcessing sociology:  96%|█████████▌| 192/201 [54:58<02:36, 17.42s/it]Device set to use cuda:0\nProcessing sociology:  96%|█████████▌| 193/201 [55:15<02:18, 17.32s/it]Device set to use cuda:0\nProcessing sociology:  97%|█████████▋| 194/201 [55:33<02:02, 17.50s/it]Device set to use cuda:0\nProcessing sociology:  97%|█████████▋| 195/201 [55:50<01:45, 17.63s/it]Device set to use cuda:0\nProcessing sociology:  98%|█████████▊| 196/201 [56:09<01:28, 17.79s/it]Device set to use cuda:0\nProcessing sociology:  98%|█████████▊| 197/201 [56:28<01:12, 18.14s/it]Device set to use cuda:0\nProcessing sociology:  99%|█████████▊| 198/201 [56:45<00:53, 17.87s/it]Device set to use cuda:0\nProcessing sociology:  99%|█████████▉| 199/201 [57:02<00:35, 17.62s/it]Device set to use cuda:0\nProcessing sociology: 100%|█████████▉| 200/201 [57:20<00:17, 17.74s/it]Device set to use cuda:0\nProcessing sociology: 100%|██████████| 201/201 [57:37<00:00, 17.20s/it]","output_type":"stream"},{"name":"stdout","text":"MMLU Task Accuracy (task=sociology): 0.27860696517412936\nOverall MMLU Accuracy: 0.27860696517412936\n0.27860696517412936\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}