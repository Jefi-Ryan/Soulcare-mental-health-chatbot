{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q -U deepeval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:55:14.996163Z","iopub.execute_input":"2025-01-08T07:55:14.996369Z","iopub.status.idle":"2025-01-08T07:55:32.403956Z","shell.execute_reply.started":"2025-01-08T07:55:14.996349Z","shell.execute_reply":"2025-01-08T07:55:32.403104Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m576.5/576.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.4/326.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndistributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%capture\n!pip install --no-deps xformers trl peft accelerate bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:55:32.404826Z","iopub.execute_input":"2025-01-08T07:55:32.405163Z","iopub.status.idle":"2025-01-08T07:55:37.304489Z","shell.execute_reply.started":"2025-01-08T07:55:32.405140Z","shell.execute_reply":"2025-01-08T07:55:37.303564Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install -q -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:55:37.305346Z","iopub.execute_input":"2025-01-08T07:55:37.305560Z","iopub.status.idle":"2025-01-08T07:55:40.497835Z","shell.execute_reply.started":"2025-01-08T07:55:37.305542Z","shell.execute_reply":"2025-01-08T07:55:40.496723Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install -q --upgrade peft trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:55:40.498842Z","iopub.execute_input":"2025-01-08T07:55:40.499193Z","iopub.status.idle":"2025-01-08T07:55:54.600987Z","shell.execute_reply.started":"2025-01-08T07:55:40.499163Z","shell.execute_reply":"2025-01-08T07:55:54.599927Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install -q lm-format-enforcer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:55:54.601964Z","iopub.execute_input":"2025-01-08T07:55:54.602215Z","iopub.status.idle":"2025-01-08T07:55:58.231573Z","shell.execute_reply.started":"2025-01-08T07:55:54.602195Z","shell.execute_reply":"2025-01-08T07:55:58.230604Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install -q --upgrade pymilvus openai requests tqdm pandas deepeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:55:58.233849Z","iopub.execute_input":"2025-01-08T07:55:58.234121Z","iopub.status.idle":"2025-01-08T07:56:11.281820Z","shell.execute_reply.started":"2025-01-08T07:55:58.234100Z","shell.execute_reply":"2025-01-08T07:56:11.280997Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.3 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nread_key = user_secrets.get_secret(\"HF_READ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:56:11.283273Z","iopub.execute_input":"2025-01-08T07:56:11.283551Z","iopub.status.idle":"2025-01-08T07:56:11.432543Z","shell.execute_reply.started":"2025-01-08T07:56:11.283530Z","shell.execute_reply":"2025-01-08T07:56:11.431904Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token= read_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:56:11.433324Z","iopub.execute_input":"2025-01-08T07:56:11.433523Z","iopub.status.idle":"2025-01-08T07:56:11.941145Z","shell.execute_reply.started":"2025-01-08T07:56:11.433505Z","shell.execute_reply":"2025-01-08T07:56:11.940490Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import json\nfrom pydantic import BaseModel\nimport torch\nfrom lmformatenforcer import JsonSchemaParser\nfrom lmformatenforcer.integrations.transformers import (\n    build_transformers_prefix_allowed_tokens_fn,\n)\nfrom transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n\nfrom deepeval.models import DeepEvalBaseLLM\n\n\nclass CustomModel(DeepEvalBaseLLM):\n    def __init__(self):\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_use_double_quant=True,\n        )\n\n        model_4bit = AutoModelForCausalLM.from_pretrained(\n            \"unsloth/gemma-2b-it-bnb-4bit\",\n            device_map=\"auto\",\n            quantization_config=quantization_config,\n        )\n        tokenizer = AutoTokenizer.from_pretrained(\n            \"unsloth/gemma-2b-it-bnb-4bit\"\n        )\n\n        self.model = model_4bit\n        self.tokenizer = tokenizer\n\n    def load_model(self):\n        return self.model\n\n    def generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n        model = self.load_model()\n        # Initialize the pipeline for text generation\n        gen_pipeline = pipeline(\n            \"text-generation\",\n            model=model,\n            tokenizer=self.tokenizer,\n            use_cache=True,\n            device_map=\"auto\",\n            max_length=2500,\n            do_sample=True,\n            top_k=5,\n            num_return_sequences=1,\n            eos_token_id=self.tokenizer.eos_token_id,\n            pad_token_id=self.tokenizer.eos_token_id,\n        )\n\n        # Create parser required for JSON confinement using lmformatenforcer\n        parser = JsonSchemaParser(schema.schema())\n        prefix_function = build_transformers_prefix_allowed_tokens_fn(\n            gen_pipeline.tokenizer, parser\n        )\n\n        # Output and load valid JSON\n        output_dict = gen_pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n        output = output_dict[0][\"generated_text\"][len(prompt):]\n        json_result = json.loads(output)\n\n        # Return valid JSON object according to the schema DeepEval supplied\n        return schema(**json_result)\n\n    async def a_generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n        return self.generate(prompt, schema)\n\n    def get_model_name(self):\n        return \"Gemma-2B Unsloth\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:56:11.941929Z","iopub.execute_input":"2025-01-08T07:56:11.942222Z","iopub.status.idle":"2025-01-08T07:56:25.432828Z","shell.execute_reply.started":"2025-01-08T07:56:11.942193Z","shell.execute_reply":"2025-01-08T07:56:25.432142Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from deepeval.benchmarks import MMLU\nfrom deepeval.benchmarks.tasks import MMLUTask\n\ncustom_llm = CustomModel()\n\nmm_tasks = [\n    MMLUTask.MORAL_DISPUTES,\n]\n\nbenchmark = MMLU(\n    tasks=mm_tasks,\n    n_shots=3\n)\n\n\nbenchmark.evaluate(model=custom_llm)\nprint(benchmark.overall_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:56:25.433662Z","iopub.execute_input":"2025-01-08T07:56:25.433997Z","iopub.status.idle":"2025-01-08T09:29:58.348572Z","shell.execute_reply.started":"2025-01-08T07:56:25.433954Z","shell.execute_reply":"2025-01-08T09:29:58.347780Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01919b6cc9f3468db624540e0f43183e"}},"metadata":{}},{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n  warnings.warn(warning_msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.07G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad663b15e62346e8beab041a3fc09e7e"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efa21f3366244541b0b70f5efa843130"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/40.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9806061e346e46c790d43f38f115fbc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0860557dae3d4ff38d00b97c89744eb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99d10635e60a45c78985fbcf0c062037"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027ab5df2cf6448d893b46dd098ae09a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/28.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76b256c74c74ef1b88882cce639ba11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mmlu.py:   0%|          | 0.00/5.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebba893b1c604b0bb9e07b04f265d51e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/166M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726385aff28d4284944c14773aae27a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/346 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb363f1e79924fdf80317318370846c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/38 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ea948fe7364ac5b94924c7ffa67d90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81a17c80160d461b9caaff4bbd45428f"}},"metadata":{}},{"name":"stderr","text":"Processing moral_disputes:   0%|          | 0/346 [00:00<?, ?it/s]Device set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nProcessing moral_disputes:   0%|          | 1/346 [00:17<1:42:18, 17.79s/it]Device set to use cuda:0\nProcessing moral_disputes:   1%|          | 2/346 [00:34<1:37:33, 17.02s/it]Device set to use cuda:0\nProcessing moral_disputes:   1%|          | 3/346 [00:50<1:35:48, 16.76s/it]Device set to use cuda:0\nProcessing moral_disputes:   1%|          | 4/346 [01:07<1:34:50, 16.64s/it]Device set to use cuda:0\nProcessing moral_disputes:   1%|▏         | 5/346 [01:22<1:32:14, 16.23s/it]Device set to use cuda:0\nProcessing moral_disputes:   2%|▏         | 6/346 [01:39<1:32:19, 16.29s/it]Device set to use cuda:0\nProcessing moral_disputes:   2%|▏         | 7/346 [01:55<1:31:28, 16.19s/it]Device set to use cuda:0\nProcessing moral_disputes:   2%|▏         | 8/346 [02:10<1:30:19, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:   3%|▎         | 9/346 [02:26<1:29:51, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:   3%|▎         | 10/346 [02:42<1:29:25, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:   3%|▎         | 11/346 [02:59<1:30:08, 16.14s/it]Device set to use cuda:0\nProcessing moral_disputes:   3%|▎         | 12/346 [03:15<1:29:33, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:   4%|▍         | 13/346 [03:30<1:28:15, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:   4%|▍         | 14/346 [03:47<1:29:13, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:   4%|▍         | 15/346 [04:03<1:29:17, 16.19s/it]Device set to use cuda:0\nProcessing moral_disputes:   5%|▍         | 16/346 [04:19<1:28:45, 16.14s/it]Device set to use cuda:0\nProcessing moral_disputes:   5%|▍         | 17/346 [04:35<1:28:13, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:   5%|▌         | 18/346 [04:51<1:28:00, 16.10s/it]Device set to use cuda:0\nProcessing moral_disputes:   5%|▌         | 19/346 [05:08<1:28:30, 16.24s/it]Device set to use cuda:0\nProcessing moral_disputes:   6%|▌         | 20/346 [05:24<1:28:20, 16.26s/it]Device set to use cuda:0\nProcessing moral_disputes:   6%|▌         | 21/346 [05:40<1:28:07, 16.27s/it]Device set to use cuda:0\nProcessing moral_disputes:   6%|▋         | 22/346 [05:56<1:27:36, 16.22s/it]Device set to use cuda:0\nProcessing moral_disputes:   7%|▋         | 23/346 [06:12<1:26:07, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:   7%|▋         | 24/346 [06:29<1:26:48, 16.17s/it]Device set to use cuda:0\nProcessing moral_disputes:   7%|▋         | 25/346 [06:45<1:26:21, 16.14s/it]Device set to use cuda:0\nProcessing moral_disputes:   8%|▊         | 26/346 [07:00<1:25:21, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:   8%|▊         | 27/346 [07:16<1:25:03, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:   8%|▊         | 28/346 [07:33<1:25:59, 16.23s/it]Device set to use cuda:0\nProcessing moral_disputes:   8%|▊         | 29/346 [07:49<1:25:18, 16.15s/it]Device set to use cuda:0\nProcessing moral_disputes:   9%|▊         | 30/346 [08:05<1:24:56, 16.13s/it]Device set to use cuda:0\nProcessing moral_disputes:   9%|▉         | 31/346 [08:20<1:23:36, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:   9%|▉         | 32/346 [08:37<1:23:55, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  10%|▉         | 33/346 [08:53<1:23:43, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  10%|▉         | 34/346 [09:09<1:23:00, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  10%|█         | 35/346 [09:25<1:23:17, 16.07s/it]Device set to use cuda:0\nProcessing moral_disputes:  10%|█         | 36/346 [09:41<1:22:21, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  11%|█         | 37/346 [09:57<1:22:56, 16.11s/it]Device set to use cuda:0\nProcessing moral_disputes:  11%|█         | 38/346 [10:13<1:22:18, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  11%|█▏        | 39/346 [10:30<1:22:53, 16.20s/it]Device set to use cuda:0\nProcessing moral_disputes:  12%|█▏        | 40/346 [10:46<1:22:34, 16.19s/it]Device set to use cuda:0\nProcessing moral_disputes:  12%|█▏        | 41/346 [11:02<1:22:09, 16.16s/it]Device set to use cuda:0\nProcessing moral_disputes:  12%|█▏        | 42/346 [11:18<1:21:22, 16.06s/it]Device set to use cuda:0\nProcessing moral_disputes:  12%|█▏        | 43/346 [11:34<1:21:03, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  13%|█▎        | 44/346 [11:50<1:20:40, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  13%|█▎        | 45/346 [12:06<1:20:19, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  13%|█▎        | 46/346 [12:21<1:19:48, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  14%|█▎        | 47/346 [12:37<1:19:36, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  14%|█▍        | 48/346 [12:53<1:19:02, 15.91s/it]Device set to use cuda:0\nProcessing moral_disputes:  14%|█▍        | 49/346 [13:10<1:19:27, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  14%|█▍        | 50/346 [13:26<1:19:03, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  15%|█▍        | 51/346 [13:42<1:19:05, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  15%|█▌        | 52/346 [13:58<1:18:31, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  15%|█▌        | 53/346 [14:13<1:17:54, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  16%|█▌        | 54/346 [14:29<1:17:43, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  16%|█▌        | 55/346 [14:45<1:16:35, 15.79s/it]Device set to use cuda:0\nProcessing moral_disputes:  16%|█▌        | 56/346 [15:01<1:17:04, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  16%|█▋        | 57/346 [15:18<1:17:37, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  17%|█▋        | 58/346 [15:33<1:16:55, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  17%|█▋        | 59/346 [15:49<1:16:33, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  17%|█▋        | 60/346 [16:06<1:16:26, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  18%|█▊        | 61/346 [16:21<1:15:46, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  18%|█▊        | 62/346 [16:37<1:15:24, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  18%|█▊        | 63/346 [16:53<1:14:52, 15.88s/it]Device set to use cuda:0\nProcessing moral_disputes:  18%|█▊        | 64/346 [17:09<1:15:15, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  19%|█▉        | 65/346 [17:26<1:15:20, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  19%|█▉        | 66/346 [17:41<1:14:24, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  19%|█▉        | 67/346 [17:58<1:14:56, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  20%|█▉        | 68/346 [18:13<1:13:34, 15.88s/it]Device set to use cuda:0\nProcessing moral_disputes:  20%|█▉        | 69/346 [18:30<1:14:13, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  20%|██        | 70/346 [18:45<1:13:21, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  21%|██        | 71/346 [19:01<1:12:51, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  21%|██        | 72/346 [19:17<1:12:47, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  21%|██        | 73/346 [19:34<1:13:56, 16.25s/it]Device set to use cuda:0\nProcessing moral_disputes:  21%|██▏       | 74/346 [19:50<1:14:02, 16.33s/it]Device set to use cuda:0\nProcessing moral_disputes:  22%|██▏       | 75/346 [20:07<1:14:04, 16.40s/it]Device set to use cuda:0\nProcessing moral_disputes:  22%|██▏       | 76/346 [20:23<1:13:05, 16.24s/it]Device set to use cuda:0\nProcessing moral_disputes:  22%|██▏       | 77/346 [20:39<1:12:41, 16.21s/it]Device set to use cuda:0\nProcessing moral_disputes:  23%|██▎       | 78/346 [20:55<1:11:52, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  23%|██▎       | 79/346 [21:11<1:11:27, 16.06s/it]Device set to use cuda:0\nProcessing moral_disputes:  23%|██▎       | 80/346 [21:27<1:11:42, 16.18s/it]Device set to use cuda:0\nProcessing moral_disputes:  23%|██▎       | 81/346 [21:43<1:11:08, 16.11s/it]Device set to use cuda:0\nProcessing moral_disputes:  24%|██▎       | 82/346 [21:59<1:10:49, 16.10s/it]Device set to use cuda:0\nProcessing moral_disputes:  24%|██▍       | 83/346 [22:15<1:10:35, 16.10s/it]Device set to use cuda:0\nProcessing moral_disputes:  25%|██▌       | 88/346 [23:37<1:09:52, 16.25s/it]Device set to use cuda:0\nProcessing moral_disputes:  26%|██▌       | 89/346 [23:53<1:09:07, 16.14s/it]Device set to use cuda:0\nProcessing moral_disputes:  26%|██▌       | 90/346 [24:09<1:08:51, 16.14s/it]Device set to use cuda:0\nProcessing moral_disputes:  26%|██▋       | 91/346 [24:25<1:08:56, 16.22s/it]Device set to use cuda:0\nProcessing moral_disputes:  27%|██▋       | 92/346 [24:42<1:08:49, 16.26s/it]Device set to use cuda:0\nProcessing moral_disputes:  27%|██▋       | 93/346 [24:57<1:08:05, 16.15s/it]Device set to use cuda:0\nProcessing moral_disputes:  27%|██▋       | 94/346 [25:14<1:08:18, 16.27s/it]Device set to use cuda:0\nProcessing moral_disputes:  27%|██▋       | 95/346 [25:30<1:07:23, 16.11s/it]Device set to use cuda:0\nProcessing moral_disputes:  28%|██▊       | 96/346 [25:46<1:07:39, 16.24s/it]Device set to use cuda:0\nProcessing moral_disputes:  28%|██▊       | 97/346 [26:02<1:07:05, 16.17s/it]Device set to use cuda:0\nProcessing moral_disputes:  28%|██▊       | 98/346 [26:18<1:06:15, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  29%|██▊       | 99/346 [26:34<1:06:16, 16.10s/it]Device set to use cuda:0\nProcessing moral_disputes:  29%|██▉       | 100/346 [26:50<1:05:41, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  29%|██▉       | 101/346 [27:06<1:05:31, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  29%|██▉       | 102/346 [27:23<1:05:33, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  30%|██▉       | 103/346 [27:38<1:04:40, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  30%|███       | 104/346 [27:54<1:04:28, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  30%|███       | 105/346 [28:10<1:04:04, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  31%|███       | 106/346 [28:26<1:04:08, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  31%|███       | 107/346 [28:42<1:03:40, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  31%|███       | 108/346 [28:58<1:03:37, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  32%|███▏      | 109/346 [29:14<1:03:03, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  32%|███▏      | 110/346 [29:31<1:03:36, 16.17s/it]Device set to use cuda:0\nProcessing moral_disputes:  32%|███▏      | 111/346 [29:47<1:03:53, 16.31s/it]Device set to use cuda:0\nProcessing moral_disputes:  32%|███▏      | 112/346 [30:03<1:03:23, 16.25s/it]Device set to use cuda:0\nProcessing moral_disputes:  33%|███▎      | 113/346 [30:20<1:03:03, 16.24s/it]Device set to use cuda:0\nProcessing moral_disputes:  33%|███▎      | 114/346 [30:36<1:02:20, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  33%|███▎      | 115/346 [30:52<1:01:53, 16.07s/it]Device set to use cuda:0\nProcessing moral_disputes:  34%|███▎      | 116/346 [31:07<1:01:29, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  34%|███▍      | 117/346 [31:23<1:00:55, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  34%|███▍      | 118/346 [31:39<1:00:36, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  34%|███▍      | 119/346 [31:55<1:00:05, 15.88s/it]Device set to use cuda:0\nProcessing moral_disputes:  35%|███▍      | 120/346 [32:11<1:00:30, 16.06s/it]Device set to use cuda:0\nProcessing moral_disputes:  35%|███▍      | 121/346 [32:27<1:00:11, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  35%|███▌      | 122/346 [32:43<59:35, 15.96s/it]  Device set to use cuda:0\nProcessing moral_disputes:  36%|███▌      | 123/346 [32:59<59:38, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  36%|███▌      | 124/346 [33:16<1:00:02, 16.23s/it]Device set to use cuda:0\nProcessing moral_disputes:  36%|███▌      | 125/346 [33:33<1:00:06, 16.32s/it]Device set to use cuda:0\nProcessing moral_disputes:  36%|███▋      | 126/346 [33:49<59:36, 16.26s/it]  Device set to use cuda:0\nProcessing moral_disputes:  37%|███▋      | 127/346 [34:04<58:39, 16.07s/it]Device set to use cuda:0\nProcessing moral_disputes:  37%|███▋      | 128/346 [34:21<58:55, 16.22s/it]Device set to use cuda:0\nProcessing moral_disputes:  37%|███▋      | 129/346 [34:38<59:36, 16.48s/it]Device set to use cuda:0\nProcessing moral_disputes:  38%|███▊      | 130/346 [34:54<58:36, 16.28s/it]Device set to use cuda:0\nProcessing moral_disputes:  38%|███▊      | 131/346 [35:10<58:15, 16.26s/it]Device set to use cuda:0\nProcessing moral_disputes:  38%|███▊      | 132/346 [35:26<57:14, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  38%|███▊      | 133/346 [35:42<57:14, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  39%|███▊      | 134/346 [35:58<56:38, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  39%|███▉      | 135/346 [36:13<55:51, 15.88s/it]Device set to use cuda:0\nProcessing moral_disputes:  39%|███▉      | 136/346 [36:29<55:43, 15.92s/it]Device set to use cuda:0\nProcessing moral_disputes:  40%|███▉      | 137/346 [36:45<55:30, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  40%|███▉      | 138/346 [37:01<55:02, 15.88s/it]Device set to use cuda:0\nProcessing moral_disputes:  40%|████      | 139/346 [37:17<54:57, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  40%|████      | 140/346 [37:33<54:56, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  41%|████      | 141/346 [37:49<54:51, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  41%|████      | 142/346 [38:06<55:00, 16.18s/it]Device set to use cuda:0\nProcessing moral_disputes:  41%|████▏     | 143/346 [38:22<54:16, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  42%|████▏     | 144/346 [38:37<53:53, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  42%|████▏     | 145/346 [38:53<53:36, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  42%|████▏     | 146/346 [39:09<53:07, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  42%|████▏     | 147/346 [39:25<52:54, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  43%|████▎     | 148/346 [39:41<52:34, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  43%|████▎     | 149/346 [39:57<52:13, 15.91s/it]Device set to use cuda:0\nProcessing moral_disputes:  43%|████▎     | 150/346 [40:13<52:29, 16.07s/it]Device set to use cuda:0\nProcessing moral_disputes:  44%|████▎     | 151/346 [40:29<51:56, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  44%|████▍     | 152/346 [40:46<52:02, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  44%|████▍     | 153/346 [41:02<51:48, 16.10s/it]Device set to use cuda:0\nProcessing moral_disputes:  45%|████▍     | 154/346 [41:17<51:03, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  45%|████▍     | 155/346 [41:33<50:42, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  45%|████▌     | 156/346 [41:49<50:32, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  45%|████▌     | 157/346 [42:05<49:59, 15.87s/it]Device set to use cuda:0\nProcessing moral_disputes:  46%|████▌     | 158/346 [42:21<50:03, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  46%|████▌     | 159/346 [42:37<49:32, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  46%|████▌     | 160/346 [42:53<49:37, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  47%|████▋     | 161/346 [43:09<49:46, 16.15s/it]Device set to use cuda:0\nProcessing moral_disputes:  47%|████▋     | 162/346 [43:25<48:52, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  47%|████▋     | 163/346 [43:41<48:42, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  47%|████▋     | 164/346 [43:57<48:14, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  48%|████▊     | 165/346 [44:13<48:19, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  48%|████▊     | 166/346 [44:29<47:59, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  48%|████▊     | 167/346 [44:45<47:47, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  49%|████▊     | 168/346 [45:01<47:50, 16.13s/it]Device set to use cuda:0\nProcessing moral_disputes:  49%|████▉     | 169/346 [45:17<47:25, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  49%|████▉     | 170/346 [45:33<46:37, 15.89s/it]Device set to use cuda:0\nProcessing moral_disputes:  49%|████▉     | 171/346 [45:49<46:38, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  50%|████▉     | 172/346 [46:05<46:44, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  50%|█████     | 173/346 [46:22<46:53, 16.26s/it]Device set to use cuda:0\nProcessing moral_disputes:  50%|█████     | 174/346 [46:38<46:18, 16.16s/it]Device set to use cuda:0\nProcessing moral_disputes:  51%|█████     | 175/346 [46:54<45:49, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  51%|█████     | 176/346 [47:10<45:32, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  51%|█████     | 177/346 [47:26<45:32, 16.17s/it]Device set to use cuda:0\nProcessing moral_disputes:  51%|█████▏    | 178/346 [47:42<45:08, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  52%|█████▏    | 179/346 [47:58<44:35, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  52%|█████▏    | 180/346 [48:14<43:53, 15.86s/it]Device set to use cuda:0\nProcessing moral_disputes:  52%|█████▏    | 181/346 [48:29<43:37, 15.86s/it]Device set to use cuda:0\nProcessing moral_disputes:  53%|█████▎    | 182/346 [48:46<43:57, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  53%|█████▎    | 183/346 [49:02<43:37, 16.06s/it]Device set to use cuda:0\nProcessing moral_disputes:  53%|█████▎    | 184/346 [49:19<43:52, 16.25s/it]Device set to use cuda:0\nProcessing moral_disputes:  53%|█████▎    | 185/346 [49:35<43:29, 16.21s/it]Device set to use cuda:0\nProcessing moral_disputes:  54%|█████▍    | 186/346 [49:51<43:09, 16.18s/it]Device set to use cuda:0\nProcessing moral_disputes:  54%|█████▍    | 187/346 [50:07<43:05, 16.26s/it]Device set to use cuda:0\nProcessing moral_disputes:  54%|█████▍    | 188/346 [50:24<42:44, 16.23s/it]Device set to use cuda:0\nProcessing moral_disputes:  55%|█████▍    | 189/346 [50:39<41:51, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  55%|█████▍    | 190/346 [50:55<41:44, 16.06s/it]Device set to use cuda:0\nProcessing moral_disputes:  55%|█████▌    | 191/346 [51:11<40:57, 15.86s/it]Device set to use cuda:0\nProcessing moral_disputes:  55%|█████▌    | 192/346 [51:27<41:03, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  56%|█████▌    | 193/346 [51:43<40:46, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  56%|█████▌    | 194/346 [51:59<40:34, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  56%|█████▋    | 195/346 [52:15<40:19, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  57%|█████▋    | 196/346 [52:30<39:33, 15.82s/it]Device set to use cuda:0\nProcessing moral_disputes:  57%|█████▋    | 197/346 [52:47<39:32, 15.92s/it]Device set to use cuda:0\nProcessing moral_disputes:  57%|█████▋    | 198/346 [53:03<39:26, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  58%|█████▊    | 199/346 [53:19<39:04, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  58%|█████▊    | 200/346 [53:35<38:51, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  58%|█████▊    | 201/346 [53:50<38:27, 15.91s/it]Device set to use cuda:0\nProcessing moral_disputes:  58%|█████▊    | 202/346 [54:07<38:31, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  59%|█████▊    | 203/346 [54:23<38:20, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  59%|█████▉    | 204/346 [54:39<37:56, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  59%|█████▉    | 205/346 [54:55<37:32, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  60%|█████▉    | 206/346 [55:11<37:20, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  60%|█████▉    | 207/346 [55:27<37:02, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  60%|██████    | 208/346 [55:43<37:03, 16.11s/it]Device set to use cuda:0\nProcessing moral_disputes:  60%|██████    | 209/346 [55:59<36:33, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  61%|██████    | 210/346 [56:15<36:26, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  61%|██████    | 211/346 [56:31<36:12, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  61%|██████▏   | 212/346 [56:48<36:06, 16.17s/it]Device set to use cuda:0\nProcessing moral_disputes:  62%|██████▏   | 213/346 [57:03<35:39, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  62%|██████▏   | 214/346 [57:20<35:52, 16.31s/it]Device set to use cuda:0\nProcessing moral_disputes:  62%|██████▏   | 215/346 [57:36<35:20, 16.19s/it]Device set to use cuda:0\nProcessing moral_disputes:  62%|██████▏   | 216/346 [57:53<35:33, 16.41s/it]Device set to use cuda:0\nProcessing moral_disputes:  63%|██████▎   | 217/346 [58:09<35:00, 16.28s/it]Device set to use cuda:0\nProcessing moral_disputes:  63%|██████▎   | 218/346 [58:25<34:19, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  63%|██████▎   | 219/346 [58:41<33:59, 16.06s/it]Device set to use cuda:0\nProcessing moral_disputes:  64%|██████▎   | 220/346 [58:57<34:01, 16.20s/it]Device set to use cuda:0\nProcessing moral_disputes:  64%|██████▍   | 221/346 [59:13<33:17, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  64%|██████▍   | 222/346 [59:29<33:08, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  64%|██████▍   | 223/346 [59:45<32:36, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  65%|██████▍   | 224/346 [1:00:01<32:42, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  65%|██████▌   | 225/346 [1:00:18<32:53, 16.31s/it]Device set to use cuda:0\nProcessing moral_disputes:  65%|██████▌   | 226/346 [1:00:33<32:01, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  66%|██████▌   | 227/346 [1:00:49<31:48, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  66%|██████▌   | 228/346 [1:01:05<31:07, 15.83s/it]Device set to use cuda:0\nProcessing moral_disputes:  66%|██████▌   | 229/346 [1:01:22<31:31, 16.17s/it]Device set to use cuda:0\nProcessing moral_disputes:  66%|██████▋   | 230/346 [1:01:38<31:32, 16.31s/it]Device set to use cuda:0\nProcessing moral_disputes:  67%|██████▋   | 231/346 [1:01:54<30:44, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  67%|██████▋   | 232/346 [1:02:09<30:16, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  67%|██████▋   | 233/346 [1:02:25<30:06, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  68%|██████▊   | 234/346 [1:02:41<29:42, 15.92s/it]Device set to use cuda:0\nProcessing moral_disputes:  68%|██████▊   | 235/346 [1:02:57<29:36, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  68%|██████▊   | 236/346 [1:03:13<29:07, 15.89s/it]Device set to use cuda:0\nProcessing moral_disputes:  68%|██████▊   | 237/346 [1:03:30<29:24, 16.19s/it]Device set to use cuda:0\nProcessing moral_disputes:  69%|██████▉   | 238/346 [1:03:46<28:59, 16.11s/it]Device set to use cuda:0\nProcessing moral_disputes:  69%|██████▉   | 239/346 [1:04:02<28:33, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  69%|██████▉   | 240/346 [1:04:18<28:31, 16.14s/it]Device set to use cuda:0\nProcessing moral_disputes:  70%|██████▉   | 241/346 [1:04:34<28:10, 16.10s/it]Device set to use cuda:0\nProcessing moral_disputes:  70%|██████▉   | 242/346 [1:04:50<27:46, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  70%|███████   | 243/346 [1:05:06<27:24, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  71%|███████   | 244/346 [1:05:22<27:04, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  71%|███████   | 245/346 [1:05:38<26:51, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  71%|███████   | 246/346 [1:05:54<26:43, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  71%|███████▏  | 247/346 [1:06:10<26:19, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  72%|███████▏  | 248/346 [1:06:26<26:22, 16.15s/it]Device set to use cuda:0\nProcessing moral_disputes:  72%|███████▏  | 249/346 [1:06:42<26:06, 16.15s/it]Device set to use cuda:0\nProcessing moral_disputes:  72%|███████▏  | 250/346 [1:06:58<25:33, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  73%|███████▎  | 251/346 [1:07:14<25:23, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  73%|███████▎  | 252/346 [1:07:31<25:23, 16.20s/it]Device set to use cuda:0\nProcessing moral_disputes:  73%|███████▎  | 253/346 [1:07:47<25:04, 16.18s/it]Device set to use cuda:0\nProcessing moral_disputes:  73%|███████▎  | 254/346 [1:08:03<24:40, 16.09s/it]Device set to use cuda:0\nProcessing moral_disputes:  74%|███████▎  | 255/346 [1:08:18<24:01, 15.84s/it]Device set to use cuda:0\nProcessing moral_disputes:  74%|███████▍  | 256/346 [1:08:34<23:48, 15.87s/it]Device set to use cuda:0\nProcessing moral_disputes:  74%|███████▍  | 257/346 [1:08:50<23:41, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  75%|███████▍  | 258/346 [1:09:06<23:14, 15.85s/it]Device set to use cuda:0\nProcessing moral_disputes:  75%|███████▍  | 259/346 [1:09:22<23:10, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  75%|███████▌  | 260/346 [1:09:37<22:42, 15.84s/it]Device set to use cuda:0\nProcessing moral_disputes:  75%|███████▌  | 261/346 [1:09:54<22:34, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  76%|███████▌  | 262/346 [1:10:10<22:19, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  76%|███████▌  | 263/346 [1:10:25<22:00, 15.91s/it]Device set to use cuda:0\nProcessing moral_disputes:  76%|███████▋  | 264/346 [1:10:41<21:46, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  77%|███████▋  | 265/346 [1:10:57<21:27, 15.89s/it]Device set to use cuda:0\nProcessing moral_disputes:  77%|███████▋  | 266/346 [1:11:13<21:16, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  77%|███████▋  | 267/346 [1:11:29<21:01, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  77%|███████▋  | 268/346 [1:11:45<20:42, 15.92s/it]Device set to use cuda:0\nProcessing moral_disputes:  78%|███████▊  | 269/346 [1:12:01<20:27, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  78%|███████▊  | 270/346 [1:12:17<20:11, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  78%|███████▊  | 271/346 [1:12:33<19:54, 15.92s/it]Device set to use cuda:0\nProcessing moral_disputes:  79%|███████▊  | 272/346 [1:12:49<19:35, 15.88s/it]Device set to use cuda:0\nProcessing moral_disputes:  79%|███████▉  | 273/346 [1:13:05<19:21, 15.91s/it]Device set to use cuda:0\nProcessing moral_disputes:  79%|███████▉  | 274/346 [1:13:21<19:07, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  79%|███████▉  | 275/346 [1:13:36<18:48, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  80%|███████▉  | 276/346 [1:13:53<18:39, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  80%|████████  | 277/346 [1:14:09<18:24, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  80%|████████  | 278/346 [1:14:25<18:11, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  81%|████████  | 279/346 [1:14:41<17:58, 16.10s/it]Device set to use cuda:0\nProcessing moral_disputes:  81%|████████  | 280/346 [1:14:57<17:44, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  81%|████████  | 281/346 [1:15:13<17:28, 16.13s/it]Device set to use cuda:0\nProcessing moral_disputes:  82%|████████▏ | 282/346 [1:15:29<17:02, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  82%|████████▏ | 283/346 [1:15:45<16:50, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  82%|████████▏ | 284/346 [1:16:01<16:32, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  82%|████████▏ | 285/346 [1:16:17<16:12, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  83%|████████▎ | 286/346 [1:16:33<16:03, 16.05s/it]Device set to use cuda:0\nProcessing moral_disputes:  83%|████████▎ | 287/346 [1:16:49<15:33, 15.83s/it]Device set to use cuda:0\nProcessing moral_disputes:  83%|████████▎ | 288/346 [1:17:05<15:23, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  84%|████████▎ | 289/346 [1:17:21<15:10, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  84%|████████▍ | 290/346 [1:17:36<14:45, 15.81s/it]Device set to use cuda:0\nProcessing moral_disputes:  84%|████████▍ | 291/346 [1:17:52<14:31, 15.85s/it]Device set to use cuda:0\nProcessing moral_disputes:  84%|████████▍ | 292/346 [1:18:08<14:10, 15.76s/it]Device set to use cuda:0\nProcessing moral_disputes:  85%|████████▍ | 293/346 [1:18:24<14:06, 15.96s/it]Device set to use cuda:0\nProcessing moral_disputes:  85%|████████▍ | 294/346 [1:18:40<13:54, 16.04s/it]Device set to use cuda:0\nProcessing moral_disputes:  85%|████████▌ | 295/346 [1:18:56<13:28, 15.85s/it]Device set to use cuda:0\nProcessing moral_disputes:  86%|████████▌ | 296/346 [1:19:12<13:12, 15.85s/it]Device set to use cuda:0\nProcessing moral_disputes:  86%|████████▌ | 297/346 [1:19:28<12:57, 15.86s/it]Device set to use cuda:0\nProcessing moral_disputes:  86%|████████▌ | 298/346 [1:19:43<12:40, 15.83s/it]Device set to use cuda:0\nProcessing moral_disputes:  86%|████████▋ | 299/346 [1:19:59<12:23, 15.83s/it]Device set to use cuda:0\nProcessing moral_disputes:  87%|████████▋ | 300/346 [1:20:15<12:06, 15.78s/it]Device set to use cuda:0\nProcessing moral_disputes:  87%|████████▋ | 301/346 [1:20:31<11:52, 15.84s/it]Device set to use cuda:0\nProcessing moral_disputes:  87%|████████▋ | 302/346 [1:20:47<11:39, 15.91s/it]Device set to use cuda:0\nProcessing moral_disputes:  88%|████████▊ | 303/346 [1:21:03<11:29, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  88%|████████▊ | 304/346 [1:21:19<11:12, 16.02s/it]Device set to use cuda:0\nProcessing moral_disputes:  88%|████████▊ | 305/346 [1:21:35<10:57, 16.03s/it]Device set to use cuda:0\nProcessing moral_disputes:  88%|████████▊ | 306/346 [1:21:51<10:39, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  89%|████████▊ | 307/346 [1:22:07<10:20, 15.91s/it]Device set to use cuda:0\nProcessing moral_disputes:  89%|████████▉ | 308/346 [1:22:23<10:04, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  89%|████████▉ | 309/346 [1:22:39<09:49, 15.95s/it]Device set to use cuda:0\nProcessing moral_disputes:  90%|████████▉ | 310/346 [1:22:55<09:34, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  90%|████████▉ | 311/346 [1:23:10<09:16, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  90%|█████████ | 312/346 [1:23:27<09:09, 16.15s/it]Device set to use cuda:0\nProcessing moral_disputes:  90%|█████████ | 313/346 [1:23:43<08:53, 16.16s/it]Device set to use cuda:0\nProcessing moral_disputes:  91%|█████████ | 314/346 [1:23:59<08:31, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  91%|█████████ | 315/346 [1:24:15<08:13, 15.92s/it]Device set to use cuda:0\nProcessing moral_disputes:  91%|█████████▏| 316/346 [1:24:31<07:59, 15.98s/it]Device set to use cuda:0\nProcessing moral_disputes:  92%|█████████▏| 317/346 [1:24:47<07:40, 15.89s/it]Device set to use cuda:0\nProcessing moral_disputes:  92%|█████████▏| 318/346 [1:25:03<07:30, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  92%|█████████▏| 319/346 [1:25:19<07:09, 15.90s/it]Device set to use cuda:0\nProcessing moral_disputes:  92%|█████████▏| 320/346 [1:25:36<07:05, 16.35s/it]Device set to use cuda:0\nProcessing moral_disputes:  93%|█████████▎| 321/346 [1:25:53<06:50, 16.42s/it]Device set to use cuda:0\nProcessing moral_disputes:  93%|█████████▎| 322/346 [1:26:08<06:30, 16.29s/it]Device set to use cuda:0\nProcessing moral_disputes:  93%|█████████▎| 323/346 [1:26:24<06:11, 16.16s/it]Device set to use cuda:0\nProcessing moral_disputes:  94%|█████████▎| 324/346 [1:26:40<05:50, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  94%|█████████▍| 325/346 [1:26:56<05:37, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  94%|█████████▍| 326/346 [1:27:12<05:22, 16.12s/it]Device set to use cuda:0\nProcessing moral_disputes:  95%|█████████▍| 327/346 [1:27:28<05:03, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  95%|█████████▍| 328/346 [1:27:44<04:48, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  95%|█████████▌| 329/346 [1:28:00<04:31, 15.94s/it]Device set to use cuda:0\nProcessing moral_disputes:  95%|█████████▌| 330/346 [1:28:16<04:16, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  96%|█████████▌| 331/346 [1:28:32<04:00, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes:  96%|█████████▌| 332/346 [1:28:48<03:45, 16.08s/it]Device set to use cuda:0\nProcessing moral_disputes:  96%|█████████▌| 333/346 [1:29:04<03:27, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  97%|█████████▋| 334/346 [1:29:21<03:13, 16.16s/it]Device set to use cuda:0\nProcessing moral_disputes:  97%|█████████▋| 335/346 [1:29:36<02:56, 16.07s/it]Device set to use cuda:0\nProcessing moral_disputes:  97%|█████████▋| 336/346 [1:29:52<02:39, 15.93s/it]Device set to use cuda:0\nProcessing moral_disputes:  97%|█████████▋| 337/346 [1:30:08<02:22, 15.89s/it]Device set to use cuda:0\nProcessing moral_disputes:  98%|█████████▊| 338/346 [1:30:24<02:07, 15.89s/it]Device set to use cuda:0\nProcessing moral_disputes:  98%|█████████▊| 339/346 [1:30:40<01:52, 16.00s/it]Device set to use cuda:0\nProcessing moral_disputes:  98%|█████████▊| 340/346 [1:30:56<01:35, 15.97s/it]Device set to use cuda:0\nProcessing moral_disputes:  99%|█████████▊| 341/346 [1:31:12<01:19, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes:  99%|█████████▉| 342/346 [1:31:27<01:03, 15.84s/it]Device set to use cuda:0\nProcessing moral_disputes:  99%|█████████▉| 343/346 [1:31:43<00:47, 15.79s/it]Device set to use cuda:0\nProcessing moral_disputes:  99%|█████████▉| 344/346 [1:32:00<00:32, 16.01s/it]Device set to use cuda:0\nProcessing moral_disputes: 100%|█████████▉| 345/346 [1:32:16<00:15, 15.99s/it]Device set to use cuda:0\nProcessing moral_disputes: 100%|██████████| 346/346 [1:32:31<00:00, 16.05s/it]","output_type":"stream"},{"name":"stdout","text":"MMLU Task Accuracy (task=moral_disputes): 0.25722543352601157\nOverall MMLU Accuracy: 0.25722543352601157\n0.25722543352601157\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}